---
title: "Variable Selection"
author: "Nils Tinner"
date: "`r Sys.Date()`"
output: html_document
---
# Variable selection

## This File implements three methods to define the used variables in the model

First some data processing


```{r Load the Packages needed, message=FALSE, warning=FALSE, include=FALSE}
# Decide which packages you need. For this Project you need the following:
packages <- c("influxdbclient","ggplot2","tidyverse","lubridate",
              "dplyr","googledrive","caret","vip","parsnip",
              "workflows","tune","dials","stringr","terra","stars","sf",
              "doParallel","terrainr","starsExtra", "pdp", "kableExtra", "recipes","Boruta")

# Load the R script to install and load all the packages from above
source("../R/load_packages.R")
load_packages(packages)
```



```{r Data Wrangling, echo=FALSE, message=FALSE, warning=FALSE}



set.seed(123) #for reproducability
# We want to know, if a certain file already exists


# If do not exists such a file, we create it

  # Load the R script to processing the raw tif files
  source("../R/demo_download.R")
  
  # Load the R script to create the data frame "combined" which is the basis of this project
  source("../R/data_combination.R")
  
  # We run the loaded function and drop all NAs
  data_combination() #generate file

  combined <- read_csv("../data/Combined.csv") |>
    mutate(temperature = temperature-temp) |>
    drop_na()
  
combined <- dplyr::slice_sample(combined,prop = .03) #3% kept for performance

```

```{r Predictors and Recipe, message=FALSE, warning=FALSE, include=FALSE}

# Take all column-names you need as predictors from the combined file except the defined
predictors <- combined |>
  dplyr::select(-c(Log_Nr,temperature,timestamp,Name,NORD_CHTOP,OST_CHTOPO,year,month,day,hour,LV_03_E,LV_03_N)) |>
  colnames()


```

Now, a boruta algorithm is used to assess variable importance

```{r Predictors and Recipe, message=FALSE, warning=FALSE, include=FALSE}



temperature <- combined$temperature

# run the algorithm
bor <- Boruta::Boruta(
    y = temperature, 
    x = combined[, predictors],
    maxRuns = 30, # Number of iterations. Set to 30 or lower if it takes too long
    num.threads = parallel::detectCores()-1)

# obtain results: a data frame with all variables, ordered by their importance
df_bor <- Boruta::attStats(bor) |> 
  tibble::rownames_to_column() |> 
  dplyr::arrange(dplyr::desc(meanImp))

# plot the importance result  
ggplot2::ggplot(ggplot2::aes(x = reorder(rowname, meanImp), 
                             y = meanImp,
                             fill = decision), 
                data = df_bor) +
  ggplot2::geom_bar(stat = "identity", width = 0.75) + 
  ggplot2::scale_fill_manual(values = c("grey30", "tomato", "grey70")) + 
  ggplot2::labs(
    y = "Variable importance", 
    x = "",
    title = "Variable importance based on Boruta") +
  ggplot2::theme_classic() +
  ggplot2::coord_flip()


```

The Boruta algorithm takes all variables as relevant. This does not help. 

Next, a random forest stepwise backwards regression is implemented. The metric used is the RMSE with cross-validation.

```{r}




predictors_all <- combined |>
  dplyr::select(-c(Log_Nr,temperature,timestamp,Name,NORD_CHTOP,OST_CHTOPO,year,month,day,hour,LV_03_E,LV_03_N)) |>
  colnames()

predictors_current <- predictors_all


formula_local <- as.formula(paste("temperature","~", paste(predictors_all,collapse  = "+")))

pp <- recipes::recipe(formula_local,
                      data = combined) |>
    recipes::step_YeoJohnson(all_numeric(), -all_outcomes()) |> #extension of BoxCox? we will see wether that works...
    recipes::step_center(recipes::all_numeric(), -recipes::all_outcomes()) |>
    recipes::step_scale(recipes::all_numeric(), -recipes::all_outcomes())




random_forest <- caret::train(
  pp, 
  data = combined,
  method = "ranger",
  metric = "RMSE",
  trControl = trainControl(
    method = "cv",
    number = 5,
    savePredictions = "final"
    ),
  tuneGrid = expand.grid(
    .mtry = round(length(predictors_current)/3),       # default p/3
    .min.node.size = 2,         # set to 5
    .splitrule = "variance"     # default variance
    ),
  # arguments specific to "ranger" method
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 20,       
  seed = 1982
)

RMSE_OLD <- random_forest$results$RMSE


RMSE_NEW <- RMSE_OLD-0.00001
while(RMSE_OLD >= RMSE_NEW){
  RMSE_OLD <- RMSE_NEW
  RMSE_list <- tibble(name = NULL,RMSE = NULL)
  print("Current RMSE")
  print("----------------")
  print(RMSE_NEW)
  print("----------------")
for (predictor in predictors_current) {
  print("Current calculation")
  print(predictor)
  predictors_temp <- predictors_current[ !predictors_current == predictor]
  formula_local <- as.formula(paste("temperature","~", paste(predictors_temp,collapse  = "+")))
  
# Make a recipe which can be used for the lm, KNN, and Random Forest model
pp <- recipes::recipe(formula_local,
                      data = combined) |>
    recipes::step_YeoJohnson(all_numeric(), -all_outcomes()) |> #extension of BoxCox? we will see wether that works...
    recipes::step_center(recipes::all_numeric(), -recipes::all_outcomes()) |>
    recipes::step_scale(recipes::all_numeric(), -recipes::all_outcomes())

  random_forest <- caret::train(
  pp, 
  data = combined,
  method = "ranger",
  metric = "RMSE",
  trControl = trainControl(
    method = "cv",
    number = 5,
    savePredictions = "final"
    ),
  tuneGrid = expand.grid(
    .mtry = round(length(predictors_current)/3),       # default p/3
    .min.node.size = 2,         # set to 5
    .splitrule = "variance"     # default variance
    ),
  # arguments specific to "ranger" method
  replace = FALSE,
  sample.fraction = 0.5,
  num.trees = 20,       
  seed = 1982
)
  
  print("calculations pass finished")
  RMSE_list <- rbind(RMSE_list,tibble(name = predictor,RMSE = random_forest$results$RMSE))
}
  print("RMSE list of current pass")
  print(RMSE_list)
  RMSE_NEW <- RMSE_list |>
    dplyr::filter(RMSE == min(RMSE))|>
    dplyr::select(RMSE)|>
    as.numeric()
  highest_RMSE <- RMSE_list |>
    dplyr::filter(RMSE == min(RMSE))|> #take away the minimal RMSE when model is missing that parameter then min RMSE
    dplyr::select(name) |>
    as.character()
  print("rejected now:")
  print(highest_RMSE)
  if(RMSE_OLD >= RMSE_NEW){
    print("Model improved!!! Now overwriting predictors!")
  predictors_current <- predictors_current[! predictors_current %in% highest_RMSE]
  print("Current predictors")
  print(predictors_current)
  }
}
```
We had several runs and usually different layers are kicked out based on small code changes such as numbers of trees or other tuning variables. Furthermore usually only one variable is kicked out. For this reason, no definitive variable selection is made in this part.

At last, correlation between layers is checked for.


```{r}

correlation_matrix<- cor(combined[predictors],method = "spearman")
correlation_matrix[lower.tri(correlation_matrix)] <- NA

correlation_matrix <-as.data.frame(correlation_matrix) |>
  rownames_to_column("name")|>
pivot_longer(cols = -name,names_to = "name_1",values_to = "correlation") |>
  mutate(correlation = correlation^2)|>
  filter(correlation >= 0.7,
         name != name_1) |>
  arrange(desc(correlation)) 

```

Some variables do infact show a correlation higher than 0.7. Interestingly it is not between differently meaned layers but layers with the same distance but for different information: for example binary building present yes no and building height. Here, we also reach no definitive solution.
